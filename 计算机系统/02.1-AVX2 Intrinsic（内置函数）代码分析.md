---
创建时间: 2025-12-29 14:07
tags:
  - 计算机系统
status: 📝 编写中
---
这是一段非常标准的 **AVX2 Intrinsic（内置函数）** 代码。它并不是标准的 C 语法，而是直接对应 CPU 硬件指令的“宏”或“包装器”。

这段代码完美对应了你报告中提到的 **“2 指令级并行与向量化”** 章节 1。

为了让你彻底理解，我们像做“显微镜观察”一样，逐行、逐词地拆解它：

### 1. 核心概念拆解

首先，你要习惯 Intel 给这些函数起名字的规律，它们通常长这样：

_mm256_操作_后缀

- **`_mm256`**: 代表这是操作 **256位** 寄存器（即 AVX/AVX2 指令集）。
    
- **`ps`**: 代表 **P**acked **S**ingle-precision（打包的单精度浮点数）。这是最重要的后缀：
    
    - **Packed (打包)**: 表示它是向量操作（一次搞一堆），而不是 Scalar（标量，一次搞一个）。
        
    - **Single (单精度)**: 表示操作对象是 `float` (32-bit)。
        
    - _注：如果是 `pd` 就是 Packed Double (double类型)；如果是 `si256` 就是 Signed Integer (整型)。_
        

---

### 2. 逐行代码深度解析

#### 第一行：头文件



```C
#include <immintrin.h>
```

- **含义**：这不是普通的 C 标准库。这个头文件包含了所有 Intel CPU 的指令集扩展（AVX, SSE, MMX 等）。
    
- **作用**：引用它之后，编译器（GCC/Clang）才能看懂 `_mm256_...` 这些奇怪的函数，并把它们翻译成汇编语言中的 `vaddps`, `vmovaps` 等机器指令。
    

#### 第二行：步长为 8 的循环



```C
for (int i = 0; i < N; i += 8)
```

- **为什么是 8？**
    
    - AVX2 的寄存器（YMM）宽度是 **256 位**。
        
    - C 语言的 `float` 是 **32 位**。
        
    - $256 \div 32 = 8$。
        
- **微观机制**：这个循环不再是“一个一个”处理，而是“一块一块”处理。每次 `i` 增加 8，意味着处理了 `a[0]~a[7]`，下一次就是 `a[8]~a[15]`。
    

#### 第三、四行：并行加载 (Load)



```C
__m256 va = _mm256_load_ps(&a[i]);
__m256 vb = _mm256_load_ps(&b[i]);
```

- **`__m256`**:
    
    - 这是一个特殊的**数据类型**。普通的 `float` 变量里只存 1 个数，而 `__m256` 变量里紧挨着存了 **8 个 float**。它直接映射到 CPU 内部的 **YMM 寄存器**。
        
- **`&a[i]`**:
    
    - 这是内存地址的起点。比如当 `i=0` 时，它指向 `a[0]`。
        
- **`_mm256_load_ps`**:
    
    - **动作**：从内存地址 `&a[i]` 开始，连续抓取 8 个 float（共 32 字节），一把塞进寄存器 `va` 中。
        
    - **⚠️ 致命细节 (Trap)**：注意你用的是 `load_ps` 而不是 `loadu_ps`。
        
        - `load_ps` (Aligned Load): 要求内存地址必须 **32 字节对齐**（即地址必须能被 32 整除）。如果没对齐，程序会直接 **Segfault (崩溃)**。
            
        - 这就是为什么你在报告补充部分强调要用 `posix_memalign` 的原因！如果用普通的 `malloc`，这里通常需要用 `_mm256_loadu_ps` (Un-aligned)。
            

#### 第五行：并行加法 (Compute)



```C
__m256 vc = _mm256_add_ps(va, vb);
```

- **`_mm256_add_ps`**:
    
    - 这是真正的魔法时刻。CPU 内部的 ALU（算术逻辑单元）收到这一条指令后，会同时切断 8 条电路。
        
    - 它做的事情等同于：
        
        
        
        ```C
        vc[0] = va[0] + vb[0];
        vc[1] = va[1] + vb[1];
        ...
        vc[7] = va[7] + vb[7];
        ```
        
    - **耗时**：这一切发生在一个指令周期内（虽然流水线有延迟，但在吞吐量上等同于一次做完）。
        

#### 第六行：写回内存 (Store)



```C
_mm256_store_ps(&c[i], vc);
```

- **`_mm256_store_ps`**:
    
    - **动作**：把寄存器 `vc` 里刚刚算好的 8 个结果，一次性搬运回内存数组 `c` 中，从 `&c[i]` 开始的位置存放。
        
    - **要求**：同样要求 `c` 的内存地址是 32 字节对齐的。
        

---

### 3. 总结

这段代码翻译成大白话就是：

> “嘿 CPU，我要以 8 个数为一组 进行操作。
> 
> 请从内存 a 和 b 的位置，对齐地 抓取 8 个浮点数放到你的 YMM 超级寄存器里。
> 
> 然后，用一条指令把这 8 对数字同时相加。
> 
> 最后，把算好的 8 个结果，对齐地 扔回内存 c 里。”

对比你的朴素实现（每次读1个，算1个，写1个），这个操作在理论上减少了 $7/8$ 的指令发射数，虽然实际上受限于内存带宽，但也非常接近你报告中提到的 **45 倍** 加速比的来源之一 2。